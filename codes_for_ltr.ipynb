{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample code\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model, metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import scorecardpy as sc\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pls change the columns to be one-hot encoded\n",
    "merged_working = pd.get_dummies(merged_working, columns=['REASON', \"JOB\"], drop_first = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Classing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample code\n",
    "bin_count = 20\n",
    "variable = 'CLAGE'\n",
    "\n",
    "# create a copy to work on\n",
    "hmeq_data_working = hmeq_data.copy() \n",
    "\n",
    "# reduce to just the variable and the target\n",
    "hmeq_data_working = hmeq_data_working[[variable, 'BAD']]\n",
    "\n",
    "# create equal frequency bin ranges using qcut\n",
    "hmeq_data_working['Bin_Range'] = pd.qcut(hmeq_data[variable],q=bin_count, precision=0)\n",
    "\n",
    "# missing values have been assigned NaN when binning with pd.qcut \n",
    "# rename NaN to 'Missing' and create bin range for those\n",
    "hmeq_data_working['Bin_Range'] = hmeq_data_working['Bin_Range'].astype('object')\n",
    "hmeq_data_working['Bin_Range'].fillna('Missing', inplace = True)\n",
    "\n",
    "# check the counts in each bin\n",
    "hmeq_data_working.groupby('Bin_Range').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To calculate WOE and IV for class variable; this func is necessary for woe_iv_plot function which is right below this sect\n",
    "- woe_iv(data, variable_name) --> To calculate IV and WOE of the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def woe_iv(data, variable_name):\n",
    "\n",
    "    working_data = data.copy() \n",
    "\n",
    "    # missing values have been assigned NaN when binning with pd.qcut\n",
    "    # rename this bin as 'Missing' to consider into WOE calculation\n",
    "    working_data['Bin_Range'] = working_data['Bin_Range'].astype('object')\n",
    "    working_data['Bin_Range'].fillna('Missing', inplace = True)\n",
    "    \n",
    "    variable_data = pd.DataFrame()\n",
    "    variable_data['Bin_Range'] = working_data.groupby(by='Bin_Range', as_index=False).count()['Bin_Range']\n",
    "\n",
    "    variable_data['Count'] = working_data.groupby(by='Bin_Range', as_index=False).count()['BAD']\n",
    "\n",
    "    variable_data['Events'] =working_data.groupby(by='Bin_Range', as_index=False).sum()['BAD']\n",
    "\n",
    "    variable_data['Non_Events'] = variable_data['Count'] - variable_data['Events']\n",
    "\n",
    "    variable_data['%_of_Events'] = variable_data['Events']/sum(variable_data['Events'])\n",
    "\n",
    "    variable_data['%_of_Non_Events'] = variable_data['Non_Events']/sum(variable_data['Non_Events'])\n",
    "    variable_data\n",
    "\n",
    "    variable_data['WOE'] = np.log(variable_data['%_of_Non_Events'] / variable_data['%_of_Events'])\n",
    "\n",
    "    variable_data['IV'] = (variable_data['%_of_Non_Events']-variable_data['%_of_Events']) * variable_data['WOE']\n",
    "\n",
    "    IV = sum(variable_data['IV'])\n",
    "    return(IV, variable_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create function to calculate WOE, IV and plot IV**\n",
    "\n",
    "Combine the code above into a parameterised function that you can use going forward to print IV rounded to 4 decimal places and plot WOE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample code\n",
    "# create IV calc and WOE plotting function\n",
    "def woe_iv_plot(data, variable_name):\n",
    "    IV, variable_data = woe_iv(data, variable_name)\n",
    "    print('IV for', variable_name, 'with', variable_data.shape[0], 'bins:', round(IV,4))\n",
    "    ffig, ax1 = plt.subplots(figsize=(20,6))\n",
    "\n",
    "    # if 'missing' bin, do not include in plot\n",
    "\n",
    "    if variable_data['Bin_Range'].isin(['Missing']).sum() > 0:\n",
    "        sns.lineplot(data = variable_data['WOE'].iloc[0:-1], marker='o', sort = False, ax=ax1)\n",
    "    else:\n",
    "        sns.lineplot(data = variable_data['WOE'], marker='o', sort = False, ax=ax1)\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # if 'missing' bin, create the scatter plot to plot the Missing WOE data point\n",
    "    if variable_data['Bin_Range'].isin(['Missing']).sum() > 0: \n",
    "        last_point = len(variable_data['WOE']) - 1\n",
    "        scatter_plot = sns.scatterplot(x=[last_point], y=[variable_data['WOE'][last_point]], color='b', s=30, ax=ax1)\n",
    "    \n",
    "    ax2 = ax1.twinx()\n",
    "        \n",
    "    # plot the bin counts\n",
    "    sns.barplot(x = variable_data['Bin_Range'] , y = variable_data['Count'], alpha=0.5, ax = ax2, color = 'deepskyblue')\n",
    "    plt.title(\"WOE plot for \" + variable_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can use the function to do variable screening and drop variables with low IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXAMPLE OF HOW TO USE THE FUNCTION\n",
    "\n",
    "# your code here\n",
    "large_val_numeric = ['LOAN', 'MORTDUE', 'CLAGE', 'DEBTINC']\n",
    "\n",
    "# add code to obtain IV for each of the variables\n",
    "for val in large_val_numeric:\n",
    "    woe_bin_data = hmeq_data.loc[:,(val, 'BAD')]\n",
    "    woe_bin_data['Bin_Range'] = pd.qcut(hmeq_data[val],q=20)\n",
    "    woe_bin_data['Bin_Range'] = woe_bin_data['Bin_Range'].astype('object')\n",
    "    woe_bin_data['Bin_Range'].fillna('Missing', inplace = True)\n",
    "    woe_iv_plot(woe_bin_data, val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coarse Classing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To calculate WOE and IV for class variable\n",
    "- woe_iv(data, variable_name) --> To calculate IV and WOE of the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def woe_iv(data, variable_name):\n",
    "\n",
    "    working_data = data.copy() \n",
    "\n",
    "    # missing values have been assigned NaN when binning with pd.qcut\n",
    "    # rename this bin as 'Missing' to consider into WOE calculation\n",
    "    working_data['Bin_Range'] = working_data['Bin_Range'].astype('object')\n",
    "    working_data['Bin_Range'].fillna('Missing', inplace = True)\n",
    "    \n",
    "    variable_data = pd.DataFrame()\n",
    "    variable_data['Bin_Range'] = working_data.groupby(by='Bin_Range', as_index=False).count()['Bin_Range']\n",
    "\n",
    "    variable_data['Count'] = working_data.groupby(by='Bin_Range', as_index=False).count()['BAD']\n",
    "\n",
    "    variable_data['Events'] =working_data.groupby(by='Bin_Range', as_index=False).sum()['BAD']\n",
    "\n",
    "    variable_data['Non_Events'] = variable_data['Count'] - variable_data['Events']\n",
    "\n",
    "    variable_data['%_of_Events'] = variable_data['Events']/sum(variable_data['Events'])\n",
    "\n",
    "    variable_data['%_of_Non_Events'] = variable_data['Non_Events']/sum(variable_data['Non_Events'])\n",
    "    variable_data\n",
    "\n",
    "    variable_data['WOE'] = np.log(variable_data['%_of_Non_Events'] / variable_data['%_of_Events'])\n",
    "\n",
    "    variable_data['IV'] = (variable_data['%_of_Non_Events']-variable_data['%_of_Events']) * variable_data['WOE']\n",
    "\n",
    "    IV = sum(variable_data['IV'])\n",
    "    return(IV, variable_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_working.drop('BAD', axis = 1)\n",
    "y = merged_working['BAD']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 100, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression without WOE\n",
    "- adding this in if u think it might be relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample code\n",
    "\n",
    "# create a logistic regression model and fit the training data\n",
    "logreg = LogisticRegression(solver = 'liblinear', class_weight = 'balanced')\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# print out the intercept and coeeficients as a dataframe\n",
    "coeff = logreg.coef_.reshape(-1)\n",
    "df_coeff = pd.DataFrame({'Variable': ['Intercept'] + X_train.columns.tolist(), 'coefficient': np.insert(coeff,0, logreg.intercept_[0])})\n",
    "df_coeff\n",
    "\n",
    "# concatenate intercept and coefficients to a single array\n",
    "coeff = np.concatenate([logreg.intercept_, logreg.coef_.reshape(-1)])\n",
    "# create a pandas Series with the features corresponding to the coefficients\n",
    "pd.Series(coeff, index = ['Intercept'] + X_train.columns.tolist())\n",
    "\n",
    "# check the accuracy\n",
    "y_pred = logreg.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Testing accuracy is {accuracy:.4%}')\n",
    "p_bad = y_pred.sum() / y_test.shape[0]\n",
    "print(f'Percentage of bads predicted in the test data is {p_bad:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with WOE (using scorecardpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sample code\n",
    "# split data into 70% train and 30% test\n",
    "train, test = sc.split_df(hmeq_data, y = 'BAD', ratio = .7).values()\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "## Generate WOE bins\n",
    "# automatically calculate bin ranges, bins is a dictionary\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    bins = sc.woebin(train, y = 'BAD')\n",
    "\n",
    "for variables, bindetails in bins.items():\n",
    "    print(variables, \" : \")\n",
    "    display(bindetails)\n",
    "    print(\"--\"*50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate LR with WOE encoding\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    train_woe = sc.woebin_ply(train, bins)\n",
    "    test_woe = sc.woebin_ply(test, bins)\n",
    "train_woe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model, metrics\n",
    "# sample code\n",
    "\n",
    "# create the X, y parts of data for train and test\n",
    "y_train = train_woe.loc[:, 'BAD']\n",
    "X_train = train_woe.loc[:, train_woe.columns != 'BAD']\n",
    "y_test = test_woe.loc[:, 'BAD']\n",
    "X_test = test_woe.loc[:, train_woe.columns != 'BAD']\n",
    "\n",
    "# create a logistic regression model object\n",
    "lr = linear_model.LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print(lr.coef_)\n",
    "print(lr.intercept_)\n",
    "pd.Series(np.concatenate([lr.intercept_, lr.coef_[0]]), index = np.concatenate([['intercept'], lr.feature_names_in_]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "# sample code\n",
    "\n",
    "# generate a card from the model and bins. The scores will be based on probability of default from the model\n",
    "# bins = bins created from sc.woebin\n",
    "# lr = fitted logistic regression model\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    card = sc.scorecard(bins, lr, X_train.columns, points0 = 600, odds0 = 1/20, pdo = 20, basepoints_eq0 = True)\n",
    "\n",
    "pprint.pprint(card)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate scorecard with basepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample code\n",
    "\n",
    "# generate a card from the model and bins. The scores will be based on probability of default from the model\n",
    "# bins = bins created from sc.woebin\n",
    "# lr = fitted logistic regression model\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    card = sc.scorecard(bins, lr, X_train.columns, points0 = 600, odds0 = 1/20, pdo = 20, basepoints_eq0 = False)\n",
    "\n",
    "pprint.pprint(card)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score a new appplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample code\n",
    "\n",
    "# calulate credit score for new application\n",
    "col = ['LOAN','VALUE','REASON','JOB','YOJ','DEROG','DELINQ','CLAGE','NINQ','CLNO','DEBTINC']\n",
    "val = [[88900,57264,'DebtCon','Other',16.0,0.0,0.0,221.8,0.0,16.0,36.1]]\n",
    "new_appl = pd.DataFrame(val, columns = col)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    new_appl_score = sc.scorecard_ply(new_appl, card, only_total_score = False).transpose()\n",
    "new_appl_score.index = new_appl_score.index.str.replace('_points', '')\n",
    "\n",
    "summary = pd.concat([new_appl.transpose(), new_appl_score], axis=1)\n",
    "summary.columns = ['App Value', 'Points']\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To score train and test data\n",
    "Examine the distribution of the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample code\n",
    "\n",
    "# credit score for samples in test and train\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    train_score = sc.scorecard_ply(train, card)\n",
    "    test_score = sc.scorecard_ply(test, card)\n",
    "\n",
    "# distribution of scores on train and test data\n",
    "fig, ax = plt.subplots(2, 1, figsize = (7, 8), sharex = True)\n",
    "train_score.hist(figsize = (7, 4), bins = 60, ax = ax[0])\n",
    "ax[0].set_title('train data scores', fontsize = 9)\n",
    "test_score.hist(figsize = (7, 4), bins = 60, ax = ax[1])\n",
    "ax[1].set_title('test data scores', fontsize = 9)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model performance\n",
    "**Calculate Percentage Correctly Classified measures on LR model**\n",
    "\n",
    "Using `predict` function to generate predictions based on 50% probability threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample code\n",
    "# print evaluation metrics of the model\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print('Confusion matrix:')\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "print('PCC measures:')\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance of LR with ROC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample code \n",
    "\n",
    "# evaluate the performance of the logistic regression\n",
    "train_pred = lr.predict_proba(X_train)[:, 1]\n",
    "test_pred = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# performance roc\n",
    "train_perf = sc.perf_eva(y_train, train_pred, plot_type = ['roc'], title = 'train')\n",
    "test_perf = sc.perf_eva(y_test, test_pred, plot_type = ['roc'], title = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## i cannot find code for PSI"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "is217_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
